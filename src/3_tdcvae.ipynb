{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# CODE FILES HERE\n",
    "from models.tdcvae.tdcvae import Encoder, Decoder, TD_Cvae, MODEL_NAME\n",
    "from solver import Solver\n",
    "from dataloader import DataLoader\n",
    "from directories import Directories\n",
    "from plots import plot_losses, plot_gaussian_distributions, plot_rl_kl, plot_latent_space,\\\n",
    "plot_latent_manifold, plot_prepro_params_distribution, plot_prepro_params_distribution_categories,\\\n",
    "plot_prepro_alpha_params_distribution, plot_prepro_radius_params_distribution, plot_faces_grid, plot_faces_samples_grid\n",
    "\n",
    "# SETTINGS HERE\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # to see the CUDA stack\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# supress cluttering warnings in solutions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# VARIABLES HERE\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the dataset and tune hyperparameters here!\n",
    "dataset = \"MNIST\"\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "num_generations = 30\n",
    "\n",
    "if dataset == \"MNIST\":\n",
    "    batch_size = 128\n",
    "    epochs = 2\n",
    "    hidden_dim = 500\n",
    "    z_dim = 2\n",
    "    beta = 1 if z_dim == 2 else 1\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR\n",
    "    step_config = {\n",
    "        \"step_size\" : 50,\n",
    "        \"gamma\" : 0.1 # or 0.75\n",
    "    }\n",
    "    optim_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": None\n",
    "    }\n",
    "    thetas = {\n",
    "        \"theta_1\": [-180, 180],\n",
    "        \"theta_2\": [-30, 30]\n",
    "    }\n",
    "    scales = {\n",
    "        \"scale_1\": [0.5, 0.9],\n",
    "        \"scale_2\": [0.2, 0.4]\n",
    "    }\n",
    "if dataset == \"LungScans\":\n",
    "    batch_size = 4\n",
    "    epochs = 1\n",
    "    hidden_dim = 1000\n",
    "    z_dim = 2\n",
    "    beta = 1 if z_dim == 2 else 1\n",
    "    resize = (80, 80)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR\n",
    "    step_config = {\n",
    "        \"step_size\" : 200,\n",
    "        \"gamma\" : 0.1 # or 0.75\n",
    "    }\n",
    "    optim_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": None\n",
    "    }\n",
    "    thetas = {\n",
    "        \"theta_1\": [-45, 45],\n",
    "        \"theta_2\": [-10, 10]\n",
    "    }\n",
    "    scales = {\n",
    "        \"scale_1\": [0.5, 0.9],\n",
    "        \"scale_2\": [0.2, 0.4]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++ START RUN +++++ | no save mode\n",
      "====> Epoch: 1 train set loss avg: 163.7783\n",
      "====> Test set loss avg: 132.1994\n",
      "90.17 seconds for epoch 1\n"
     ]
    }
   ],
   "source": [
    "directories = Directories(MODEL_NAME, dataset, z_dim, False)\n",
    "data_loader = DataLoader(directories, batch_size, dataset, num_generations=num_generations, thetas=thetas, fixed_thetas=True)\n",
    "model = TD_Cvae(data_loader.input_dim, hidden_dim, data_loader.input_dim, z_dim)\n",
    "solver = Solver(model, data_loader, optimizer, z_dim, epochs, beta, step_config, optim_config, lr_scheduler=lr_scheduler, num_generations=num_generations, tdcvae_mode=True)\n",
    "solver.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver = torch.load(\"../results/saved_models/model_TD_CVAE_SCALES_THETAS_MNIST_train_loss=151.99_z=2.pt\", map_location='cpu')\n",
    "#solver.model.eval()\n",
    "#load_model = True\n",
    "print(solver.z_space.shape)\n",
    "z_space_labels = solver.data_loader.prepro_params[\"theta_diff\"]\n",
    "print(solver.data_loader.prepro_params[\"theta_1\"].shape)\n",
    "print(z_space_labels[0].shape)\n",
    "print(solver.data_loader.prepro_params[\"theta_1\"][5].shape)\n",
    "print(solver.data_loader.prepro_params[\"theta_diff\"].shape)\n",
    "#print(solver.data_loader.prepro_params[\"theta_1\"][0][0:129])\n",
    "for i in range(num_generations):\n",
    "    print(solver.data_loader.prepro_params[\"theta_1\"][i][:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make something like a dict to insert for plot titles to avoid it has to be taken from solver obj and \n",
    "# instead we can los from dumb also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting train and test losses for all epochs\n",
    "plot_losses(solver, solver.train_loss_history[\"train_loss_acc\"], solver.test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the gaussian of z space and some metrics about the space\n",
    "plot_gaussian_distributions(solver, len(solver.train_loss_history[\"train_loss_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring the reconstruction loss (likelihood lower bound) and KL divergence\n",
    "DEBUG = 0\n",
    "if DEBUG:\n",
    "    for epoch, train_loss, test_loss, rl, kl in zip(solver.train_loss_history[\"epochs\"], \\\n",
    "        solver.train_loss_history[\"train_loss_acc\"], solver.test_loss_history, \\\n",
    "        solver.train_loss_history[\"recon_loss_acc\"], solver.train_loss_history[\"kl_diverg_acc\"]):\n",
    "        print(\"epoch: {}, train_loss: {:.2f}, test_loss: {:.2f}, recon. loss: {:.2f}, KL div.: {:.2f}\".format(\n",
    "            epoch, train_loss, test_loss, rl, kl))\n",
    "        print(\"overfitting: {:.2f}\".format(abs(test_loss-train_loss)))\n",
    "plot_rl_kl(solver, solver.train_loss_history[\"recon_loss_acc\"], solver.train_loss_history[\"kl_diverg_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize q(z) (latent space z)\n",
    "if solver.z_dim == 2:\n",
    "    for key in solver.data_loader.prepro_params.keys():\n",
    "        if key == \"theta_diff\" or key == \"scale_diff\" and solver.data_loader.prepro_params[key].any():\n",
    "            if key == \"theta_diff\":\n",
    "                ticks = np.arange(solver.data_loader.theta_range_2[0], solver.data_loader.theta_range_2[1]+1, 10).tolist()\n",
    "            if key == \"scale_diff\":\n",
    "                ticks = np.linspace(solver.data_loader.scale_range_2[0], solver.data_loader.scale_range_2[1], 6).tolist()\n",
    "            plot_latent_space(solver, solver.z_space[0], ticks, \"z\", key.split(\"_\")[0], solver.data_loader.prepro_params[\"theta_diff\"][0])\n",
    "else:\n",
    "    print(\"Plot of latent space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize q(y)\n",
    "if solver.z_dim == 2:\n",
    "    for key in solver.data_loader.prepro_params.keys():\n",
    "        if key == \"theta_1\" or key == \"scale_1\":\n",
    "            if key == \"theta_1\":\n",
    "                ticks = np.arange(solver.data_loader.theta_range_1[0], solver.data_loader.theta_range_1[1]+1, 30).tolist()\n",
    "            if key == \"scale_1\":\n",
    "                ticks = [round(0.1*x,1) for x in range(int(solver.data_loader.scale_range_1[0]*10),\\\n",
    "                                                       int(solver.data_loader.scale_range_1[1]+0.1)*10)]\n",
    "            plot_latent_space(solver, solver.y_space[0], ticks, \"y\", key.split(\"_\")[1], solver.data_loader.prepro_params[key][0])\n",
    "else:\n",
    "    print(\"Plot of y space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations of learned data manifold for generative models with two-dimensional latent space\n",
    "if not load_model:   \n",
    "    if solver.z_dim == 2:\n",
    "        n = 11\n",
    "        if solver.data_loader.thetas:\n",
    "            grid_x = np.linspace(-4, 4, n)\n",
    "            grid_y = np.linspace(-4, 4, n)\n",
    "        elif solver.data_loader.scales:\n",
    "            grid_x = np.linspace(-3, 3, n)\n",
    "            grid_y = np.linspace(-3, 3, n)\n",
    "        x_t = iter(solver.data_loader.train_loader).next()[0][0][0].view(-1, solver.data_loader.input_dim)\n",
    "        plot_latent_manifold(solver, \"bone\", grid_x, grid_y, n, x_t=x_t)\n",
    "    else:\n",
    "        print(\"Plot is not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart over the different theta_1/scale_1 used for y_t\n",
    "if solver.z_dim == 2:\n",
    "    for key in solver.data_loader.prepro_params.keys():\n",
    "        if key == \"theta_1\" or key == \"scale_1\":\n",
    "            if key == \"theta_1\":\n",
    "                xticks = np.arange(solver.data_loader.theta_range_1[0], solver.data_loader.theta_range_1[1]+1, 30).tolist()\n",
    "                plot_prepro_params_distribution(solver, xticks, key, \"Angle distribution for y_t\", \"Count\")\n",
    "            if key == \"scale_1\":\n",
    "                xticks = [round(0.1*x,1) for x in range(int(solver.data_loader.scale_range_1[0]*10),\\\n",
    "                                                       int(solver.data_loader.scale_range_1[1]+0.1)*10)]\n",
    "                plot_prepro_params_distribution(solver, xticks, key, \"Scaling distribution for y_t\", \"Count\")\n",
    "else:\n",
    "    print(\"Plot of y space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of angles/scales with categeries/classes of dataset as bins\n",
    "if solver.z_dim == 2 and solver.data_loader.with_labels:\n",
    "    for key in solver.data_loader.prepro_params.keys():\n",
    "        if key == \"theta_1\" or key == \"scale_1\":\n",
    "            ytitle = \"Number of elements in each bin\"\n",
    "            if key == \"theta_1\":\n",
    "                xticks = np.arange(solver.data_loader.theta_range_1[0], solver.data_loader.theta_range_1[1]+1, 30).tolist()\n",
    "                plot_prepro_params_distribution_categories(solver, xticks, key, \"Distribution of angles by labels\", ytitle)\n",
    "            if key == \"scale_1\":\n",
    "                xticks = [round(0.1*x,1) for x in range(int(solver.data_loader.scale_range_1[0]*10),\\\n",
    "                                                       int(solver.data_loader.scale_range_1[1]+0.1)*10)]\n",
    "                plot_prepro_params_distribution_categories(solver, xticks, key, \"Distribution of scales by labels\", ytitle)\n",
    "else:\n",
    "    print(\"Plot of y space not possible as dimension of z is not 2 or no labeled data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if solver.z_dim == 2:\n",
    "    for key in solver.data_loader.prepro_params.keys():\n",
    "        if key == \"theta_1\":\n",
    "            alphas = torch.atan2(torch.tensor(solver.y_space[:,0]-np.mean(solver.y_space[:,0])), torch.tensor(solver.y_space[:,1]-np.mean(solver.y_space[:,1])))/(2*np.pi)\n",
    "            alphas = [round(x,2) for x in alphas.tolist()]\n",
    "            alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "            alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "            xticks = np.arange(solver.data_loader.theta_range_1[0], solver.data_loader.theta_range_1[1]+1, 30).tolist() # theta bins\n",
    "            theta_alpha = list(zip(solver.data_loader.prepro_params[key], alphas)) # each theta_1 and alpha_1 paired\n",
    "            plot_prepro_params_distribution(solver, xticks, key, \"Archtangents distribution for y_t\", \"alpha distribution for theta_1 bins\", data=(theta_alpha, alpha_bins))\n",
    "else:\n",
    "    print(\"Plot of y space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if solver.z_dim == 2 and solver.data_loader.with_labels:\n",
    "    for key in solver.data_loader.prepro_params.keys():\n",
    "        if key == \"theta_1\":\n",
    "            alphas = torch.atan2(torch.tensor(solver.y_space[:,0]-np.mean(solver.y_space[:,0])), torch.tensor(solver.y_space[:,1]-np.mean(solver.y_space[:,1])))/(2*np.pi)\n",
    "            alphas = [round(x,2) for x in alphas.tolist()]\n",
    "            alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "            alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "            theta_bins = np.arange(solver.data_loader.theta_range_1[0], solver.data_loader.theta_range_1[1]+1, 30).tolist() # theta bins\n",
    "            theta_alpha_label = list(zip(solver.data_loader.prepro_params[key], alphas, solver.data_labels)) # each theta_1i, alpha_1i, y_i paired\n",
    "            plot_prepro_params_distribution_categories(solver, theta_bins, key, \"Distribution of archtangents by labels\", \"alpha distribution for theta_1 in bins\", data=(theta_alpha_label, alpha_bins))\n",
    "else:\n",
    "    print(\"Plot of y space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rotation\n",
    "if solver.z_dim == 2 and solver.data_loader.thetas:\n",
    "    plot_prepro_alpha_params_distribution(solver)\n",
    "else:\n",
    "    print(\"dim(z) is not 2 or rotation mode is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scaling\n",
    "if solver.z_dim == 2 and solver.data_loader.scales:\n",
    "    plot_prepro_radius_params_distribution(solver)\n",
    "else:\n",
    "    print(\"dim(z) is not 2 or scaling mode is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.radians(solver.data_loader.prepro_params[\"theta_1\"])\n",
    "#print(thetas.shape, thetas[:,0].T)\n",
    "#print(thetas[:,0].T.shape)\n",
    "#print(np.repeat(thetas[:,0].T, solver.data_loader.num_train_samples))\n",
    "#print(np.repeat(solver.data_loader.prepro_params[\"theta_1\"][:,0].T, solver.data_loader.num_train_samples))\n",
    "print(len(solver.data_loader.prepro_params[\"theta_1\"][:, 0]))\n",
    "#print(solver.y_space.shape)\n",
    "M, N, D = solver.y_space.shape\n",
    "print(solver.y_space.reshape((N, M, D)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "\n",
    "alphas = torch.atan2(torch.tensor(solver.y_space[:,:,0]-np.mean(solver.y_space[:,:,0])), torch.tensor(solver.y_space[:,:,1]-np.mean(solver.y_space[:,:,1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "# TODO:\n",
    "alphas = alphas[0,:]\n",
    "classes = solver.data_labels\n",
    "alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:]))\n",
    "\n",
    "# TODO: fix thetas...\n",
    "print(alphas.shape)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"][0] #np.radians(solver.data_loader.prepro_params[\"theta_1\"][0].T)\n",
    "print(thetas)\n",
    "print(np.min(thetas), np.max(thetas))\n",
    "\n",
    "#paired_cmap = plt.cm.get_cmap(\"Paired\", 12)\n",
    "#rvb = mcolors.LinearSegmentedColormap.from_list(\"\", paired_cmap.colors)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "#norm = (alpha_ranges - np.min(alpha_ranges))/np.ptp(alpha_ranges)\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for alpha in alphas_indices:\n",
    "        for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "            if x <= alpha and alpha < y:\n",
    "                counts[bin_idx] += 1\n",
    "                break\n",
    "    print(counts)\n",
    "    new_counts = np.zeros(len(alphas_indices))\n",
    "    asd = 0\n",
    "    for idx, count in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    print(len(thetas), len(new_counts), indices, np.min(thetas[indices]), np.max(thetas[indices]))\n",
    "    scatter = ax.scatter(thetas[indices], alphas_indices, c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "#solver = torch.load(\"../results/saved_models/model_TD_CVAE_MNIST_train_loss=88.61_z=2.pt\", map_location='cpu')\n",
    "solver = torch.load(\"../results/saved_models/model_TD_CVAE_THETAS_MNIST_train_loss=86.61_z=2.pt\", map_location='cpu')\n",
    "solver.model.eval()\n",
    "\n",
    "\n",
    "alphas = torch.atan2(torch.tensor(solver.y_space[:,0]-np.mean(solver.y_space[:,0])), torch.tensor(solver.y_space[:,1]-np.mean(solver.y_space[:,1])))/(2*np.pi)\n",
    "alphas = np.array([round(x,2) for x in alphas.tolist()])\n",
    "# TODO: problem: for each batch_size, there are num_generation (thetas, alphas), we have to take that into account!\n",
    "#thetas = np.repeat(solver.data_loader.prepro_params[\"theta_1\"], solver.data_loader.batch_size)\n",
    "classes = np.array(solver.data_labels)\n",
    "#y_space_labels = np.repeat(solver.data_loader.prepro_params[key], solver.data_loader.batch_size)\n",
    "alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "#print(solver.data_loader.prepro_params[\"theta_1\"], solver.data_loader.batch_size)\n",
    "# TODO: make alphas bins and count, but then flatten the counts, and mark by counts values where each new color begins.\n",
    "#print(np.sum(counts))\n",
    "#print(alphas.shape, len(thetas), solver.y_space.shape, len(solver.data_loader.prepro_params[\"theta_1\"]), classes)\n",
    "# move every 10, because every 10th is the angle for index 0.\n",
    "thetas = np.repeat(np.array(solver.data_loader.prepro_params[\"theta_1\"][::solver.num_generations]), solver.data_loader.batch_size)\n",
    "print(thetas.shape)\n",
    "\n",
    "paired_cmap = plt.cm.get_cmap(\"Paired\", 12)\n",
    "rvb = mcolors.LinearSegmentedColormap.from_list(\"\", paired_cmap.colors)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "norm = (alpha_ranges - np.min(alpha_ranges))/np.ptp(alpha_ranges)\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "print(alpha_bins)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for alpha in alphas_indices:\n",
    "        for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "            if x <= alpha and alpha < y:\n",
    "                counts[bin_idx] += 1\n",
    "                break\n",
    "    print(counts)\n",
    "    #print(counts.sum(), len(alphas_indices))\n",
    "    #print(counts)\n",
    "    new_counts = np.zeros(len(alphas_indices))\n",
    "    asd = 0\n",
    "    for idx, count in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        #print(asd, offset, to_fill.shape)\n",
    "        new_counts[asd:(asd+offset)] = to_fill # 0:len(to_fill), len(to_fill):len(new_to_fill)\n",
    "        asd += offset\n",
    "    print(len(new_counts))\n",
    "    scatter = ax.scatter(thetas[indices], alphas_indices, c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # compute the alphas\n",
    "    alphas = torch.zeros((solver.y_space.shape[0], solver.num_generations)) # solver.num_generations\n",
    "    for idx, gen_idx in enumerate(range(0, solver.num_generations*2, 2)): # solver.num_generations*2, 2\n",
    "        alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[:, gen_idx]-np.mean(solver.y_space[:, gen_idx])),\\\n",
    "                torch.tensor(solver.y_space[:, gen_idx+1]-np.mean(solver.y_space[:, gen_idx+1])))/(2*np.pi)\n",
    "        # normalizing alpha_{ij} = alpha_{ij} - alpha_{i0}\n",
    "        #if idx > 0:\n",
    "        #    alphas[:, idx] -= alphas[:, 0]\n",
    "    alphas = np.around(np.array(alphas), decimals=2)\n",
    "    # prepare the thetas from each batch, repeat each set of theta to span over num train samples\n",
    "    thetas = np.zeros((solver.data_loader.num_train_samples, solver.num_generations))\n",
    "    for gen in range(solver.num_generations):\n",
    "        thetas[:, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "#thetas = np.repeat(np.array(solver.data_loader.prepro_params[\"theta_1\"][::solver.num_generations]), solver.data_loader.batch_size)\n",
    "print(alphas.shape, thetas.shape)\n",
    "    # create the alphas bins, corresponding to the same number as theta bins\n",
    "    mini = np.min(alphas)\n",
    "    maxi = np.max(alphas)\n",
    "    alpha_ranges = np.around(np.linspace(mini, maxi, 13), decimals=2)\n",
    "    alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "\n",
    "    #paired_cmap = plt.cm.get_cmap(\"Paired\", 12)\n",
    "    #rvb = mcolors.LinearSegmentedColormap.from_list(\"\", paired_cmap.colors)\n",
    "    alpha_ranges = alpha_ranges[:-1]\n",
    "    #norm = (alpha_ranges - np.min(alpha_ranges))/np.ptp(alpha_ranges)\n",
    "    fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "    classes = np.array(solver.data_labels)\n",
    "    for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "        indices = np.where(classes == label)[0]\n",
    "        ax.set_title(\"class: {}\".format(label))\n",
    "        counts = np.zeros(len(alpha_bins))\n",
    "        alphas_indices = alphas[indices]\n",
    "        for i in range(alphas.shape[1]):\n",
    "            for alpha in alphas_indices[:, i]:\n",
    "                for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                    if x <= alpha and alpha < y:\n",
    "                        counts[bin_idx] += 1\n",
    "                        break\n",
    "        new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "        asd = 0\n",
    "        for idx, _ in enumerate(counts):\n",
    "            to_fill = counts[idx].repeat(counts[idx])\n",
    "            offset = len(to_fill)\n",
    "            new_counts[asd:(asd+offset)] = to_fill\n",
    "            asd += offset\n",
    "        print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "        scatter = ax.scatter(thetas[indices].flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "        fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = torch.load(\"../results/saved_models/model_TD_CVAE_THETAS_MNIST_train_loss=86.61_z=2.pt\", map_location='cpu')\n",
    "solver.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "# compute the alphas\n",
    "alphas = torch.zeros((solver.y_space.shape[0], solver.num_generations)) # solver.num_generations\n",
    "for idx, gen_idx in enumerate(range(0, solver.num_generations*2, 2)): # solver.num_generations*2, 2\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[:, gen_idx]-np.mean(solver.y_space[:, gen_idx])),\\\n",
    "            torch.tensor(solver.y_space[:, gen_idx+1]-np.mean(solver.y_space[:, gen_idx+1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "\n",
    "# prepare the thetas from each batch, repeat each set of theta to span over num train samples\n",
    "thetas = np.zeros((solver.data_loader.num_train_samples, solver.num_generations))\n",
    "# For each batch we go through num_generations iterations/encodings. Thus, \n",
    "# if num_generations is 10, for prepro_params, 0-9 is for batch 0, 10-19 for batch 1 and so on. (every time on the same batch)  \n",
    "idx = 0\n",
    "for batch_idx in range(solver.data_loader.num_train_batches):\n",
    "    start = batch_idx*solver.data_loader.batch_size\n",
    "    end = (batch_idx+1)*solver.data_loader.batch_size\n",
    "    for gen in range(solver.num_generations):\n",
    "        thetas[start:end, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][idx], solver.data_loader.batch_size)\n",
    "        idx += 1\n",
    "    #thetas[:, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "print(mini, maxi)\n",
    "for idx in range(0, alphas.shape[1]):\n",
    "    # normalizing alpha_{ij} = alpha_{ij} - alpha_{i0}\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] = np.around(alphas[:, idx] - alphas[:, 0] + (np.radians(thetas[:, 0])/(2*np.pi))-0.5, decimals=2)\n",
    "        #mini = np.min(alphas[:, idx])\n",
    "        #maxi = np.max(alphas[:, idx])\n",
    "        #print(mini, maxi)\n",
    "        #print(np.min(alphas[:, idx]), np.max(alphas[:, idx]))\n",
    "        neg_indices = np.where(alphas[:, idx] < -0.5)\n",
    "        pos_indices = np.where(alphas[:, idx] > 0.5)\n",
    "        alphas[neg_indices, idx] = mini % alphas[neg_indices, idx]\n",
    "        alphas[pos_indices, idx] = maxi % alphas[pos_indices, idx]\n",
    "        print(np.min(alphas[:, idx]), np.max(alphas[:, idx]))\n",
    "\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = np.array(solver.data_labels)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for i in range(alphas.shape[1]):\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    scatter = ax.scatter(np.radians(thetas[indices].flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "'''\n",
    "alphas = torch.atan2(torch.tensor(solver.y_space[:,:,0]-np.mean(solver.y_space[:,:,0])), torch.tensor(solver.y_space[:,:,1]-np.mean(solver.y_space[:,:,1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "# TODO:\n",
    "alphas = alphas[0,:]\n",
    "classes = solver.data_labels\n",
    "alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:]))\n",
    "\n",
    "# TODO: fix thetas...\n",
    "print(alphas.shape)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"][0] #np.radians(solver.data_loader.prepro_params[\"theta_1\"][0].T)\n",
    "print(thetas)\n",
    "print(np.min(thetas), np.max(thetas))\n",
    "\n",
    "\n",
    "# compute the alphas\n",
    "M, N, D = solver.y_space.shape\n",
    "new_y_space = solver.y_space.reshape((N, M, D))\n",
    "alphas = torch.zeros((new_y_space.shape[1], new_y_space.shape[2])) # used to be N, D\n",
    "thetas = np.zeros_like(alphas)\n",
    "#print(solver.y_space.shape, new_y_space.shape, alphas.shape)\n",
    "#print(torch.tensor(solver.y_space[: idx, 0]-np.mean(solver.y_space[:, idx, 0])).shape)\n",
    "for idx in range(solver.y_space.shape[0]):\n",
    "    print(\"haha\", (torch.tensor(new_y_space[: idx, 0]-np.mean(new_y_space[:, idx, 0]))))\n",
    "    #alphas[:, idx] = torch.atan2(torch.tensor(new_y_space[: idx, 0]-np.mean(new_y_space[:, idx, 0])),\\\n",
    "    #        torch.tensor(new_y_space[:, idx, 1]-np.mean(new_y_space[:, idx, 1])))/(2*np.pi)\n",
    "    #thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    #if idx > 0:\n",
    "    #    alphas[:, idx] -= alphas[:, 0]\n",
    "\n",
    "# TODO:oK?\n",
    "alphas = torch.zeros((solver.y_space.shape[1], solver.y_space.shape[0]))\n",
    "thetas = np.zeros_like(alphas)\n",
    "for idx in range(solver.y_space.shape[0]):\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[idx, :, 0]-np.mean(solver.y_space[idx, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[idx, :, 1]-np.mean(solver.y_space[idx, :, 1])))/(2*np.pi)\n",
    "    thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] = alphas[:, idx]\n",
    "'''\n",
    "\n",
    "# M, N, 2\n",
    "print(solver.data_loader.prepro_params[\"theta_1\"].shape)\n",
    "alphas = torch.zeros((solver.y_space.shape[1], solver.y_space.shape[0]))\n",
    "thetas = np.zeros_like(alphas)\n",
    "for idx in range(solver.y_space.shape[0]):\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[idx, :, 0]-np.mean(solver.y_space[idx, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[idx, :, 1]-np.mean(solver.y_space[idx, :, 1])))/(2*np.pi)\n",
    "    thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] -= alphas[:, 0]\n",
    "        \n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "print(mini, maxi)\n",
    "print(alphas.shape)\n",
    "\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, solver.y_space.shape[0]), decimals=2)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = np.array(solver.data_labels)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for i in range(alphas.shape[1]):\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    print(np.radians(thetas).flatten(), alphas_indices.flatten())\n",
    "    scatter = ax.scatter(np.radians(thetas).flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = np.zeros((solver.y_space.shape[0], solver.num_generations))\n",
    "centroid = np.mean(solver.y_space[:, :2], axis=0)\n",
    "# compute the euclidean distance from each point y_{ij} to the center, so the radiuses\n",
    "#print(solver.data_loader.train_loader.dataset.transform.transforms.prepro_params)\n",
    "#print(solver.data_loader.prepro_params[\"scale_1\"])\n",
    "for idx, gen_idx in enumerate(range(0, solver.num_generations*2, 2)):\n",
    "    radiuses[:, idx] = bla.cdist(solver.y_space[:, gen_idx:gen_idx+2], np.atleast_2d(centroid)).ravel()\n",
    "    if idx > 0:\n",
    "        radiuses[:, idx] -= radiuses[:, 0]\n",
    "    #radiuses = np.around(np.array(radiuses), decimals=2)\n",
    "    # prepare the scale from each batch, repeat each set of scales to span over num train samples\n",
    "#print(solver.data_loader.prepro_params)\n",
    "scales = np.zeros((solver.data_loader.num_train_samples, solver.num_generations))\n",
    "for idx in range(solver.num_generations):\n",
    "    #thetas[:, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "    scales[:, idx] = np.repeat(solver.data_loader.prepro_params[\"scale_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "    # create the alphas bins, corresponding to the same number as theta bins\n",
    "mini = np.min(radiuses)\n",
    "maxi = np.max(radiuses)\n",
    "radius_ranges = np.around(np.linspace(mini, maxi, 5), decimals=2)\n",
    "radius_bins = list(zip(radius_ranges[:-1], radius_ranges[1:]))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10, 60))\n",
    "classes = np.array(solver.data_labels)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(radius_bins))\n",
    "    radius_indices = radiuses[indices]\n",
    "    for i in range(radiuses.shape[1]):\n",
    "        for alpha in radius_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(radius_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(radius_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    scatter = ax.scatter(scales[indices, :].flatten(), radius_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_loss = solver.train_loss_history[\"train_loss_acc\"][-1]\n",
    "mode = \"\"\n",
    "print(thetas.shape)\n",
    "if solver.data_loader.thetas and solver.data_loader.scales:\n",
    "    mode = \"SCALES_THETAS_\"\n",
    "elif solver.data_loader.thetas:\n",
    "    mode += \"THETAS_\"\n",
    "elif solver.data_loader.scales:\n",
    "    mode += \"SCALES_\"\n",
    "torch.save(solver, solver.data_loader.directories.result_dir + \"/model_TD_CVAE_\" + mode + solver.data_loader.dataset + \"_train_loss=\" + \"{0:.2f}\".format(last_train_loss) + \"_z=\" + str(solver.z_dim) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
