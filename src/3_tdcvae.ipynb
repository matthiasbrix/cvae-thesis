{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# CODE FILES HERE\n",
    "from models.tdcvae.tdcvae import Encoder, Decoder, TD_Cvae, MODEL_NAME\n",
    "from solver import Solver\n",
    "from dataloader import DataLoader\n",
    "from directories import Directories\n",
    "from plots import plot_losses, plot_gaussian_distributions, plot_rl_kl, plot_latent_space,\\\n",
    "plot_latent_manifold, plot_faces_grid, plot_faces_samples_grid,\\\n",
    "plot_prepro_alpha_params_distribution, plot_prepro_radius_params_distribution\n",
    "from auxiliary import get_latent_spaces, transform_images\n",
    "from preprocessing import RandomPreprocessing, DeterministicPreprocessing\n",
    "\n",
    "# SETTINGS HERE\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # to see the CUDA stack\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# supress cluttering warnings in solutionshttp://localhost:8888/notebooks/3_tdcvae.ipynb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the dataset and tune hyperparameters here!\n",
    "dataset = \"MNIST\"\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "if dataset == \"MNIST\":\n",
    "    batch_size = 128\n",
    "    epochs = 1000\n",
    "    hidden_dim = 500\n",
    "    z_dim = 2\n",
    "    beta = 1\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR\n",
    "    step_config = {\n",
    "        \"step_size\" : 100,\n",
    "        \"gamma\" : 0.75 # or 0.1\n",
    "    }\n",
    "    optim_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": None\n",
    "    }\n",
    "    thetas = {\n",
    "        \"theta_1\": [0, 360],\n",
    "        \"theta_2\": [0, 60]\n",
    "    }\n",
    "    scales = {\n",
    "        \"scale_1\": [0.7, 1.3],\n",
    "        \"scale_2\": [0.2, 0.5]\n",
    "    }\n",
    "if dataset == \"LungScans\":\n",
    "    batch_size = 4\n",
    "    epochs = 1\n",
    "    hidden_dim = 1000\n",
    "    z_dim = 2\n",
    "    beta = 1 if z_dim == 2 else 1\n",
    "    resize = (80, 80)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR\n",
    "    step_config = {\n",
    "        \"step_size\" : 200,\n",
    "        \"gamma\" : 0.1 # or 0.75\n",
    "    }\n",
    "    optim_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": None\n",
    "    }\n",
    "    thetas = {\n",
    "        \"theta_1\": [-45, 45],\n",
    "        \"theta_2\": [-10, 10]\n",
    "    }\n",
    "    scales = {\n",
    "        \"scale_1\": [0.5, 0.9],\n",
    "        \"scale_2\": [0.2, 0.5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directories = Directories(MODEL_NAME, dataset, z_dim, False)\n",
    "data_loader = DataLoader(directories, batch_size, dataset, scales=scales, thetas=thetas)\n",
    "model = TD_Cvae(data_loader.input_dim, hidden_dim, data_loader.input_dim, z_dim, beta)\n",
    "solver = Solver(model, data_loader, optimizer, epochs, optim_config, step_config=step_config, lr_scheduler=lr_scheduler, tdcvae_mode=True, save_model_state=False)\n",
    "solver.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to load a model to continue training.\n",
    "#solver = torch.load(\"../results/tdcvae/MNIST_z=2_0/model_state.pt\")\n",
    "#solver.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to load a trained model for inference.\n",
    "#solver = torch.load(\"../results/saved_models/model_TD_CVAE_SCALES_THETAS_MNIST_train_loss=151.99_z=2.pt\", map_location='cpu')\n",
    "#solver.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make something like a dict to insert for plot titles to avoid it has to be taken from solver obj and \n",
    "# instead we can los from dumb also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting train and test losses for all epochs\n",
    "plot_losses(solver, solver.train_loss_history[\"train_loss_acc\"], solver.test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the gaussian of z space and some metrics about the space\n",
    "plot_gaussian_distributions(solver, len(solver.train_loss_history[\"train_loss_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring the reconstruction loss (likelihood lower bound) and KL divergence\n",
    "DEBUG = 1\n",
    "if DEBUG:\n",
    "    for epoch, train_loss, test_loss, rl, kl in zip(solver.train_loss_history[\"epochs\"], \\\n",
    "        solver.train_loss_history[\"train_loss_acc\"], solver.test_loss_history, \\\n",
    "        solver.train_loss_history[\"recon_loss_acc\"], solver.train_loss_history[\"kl_diverg_acc\"]):\n",
    "        print(\"epoch: {}, train_loss: {:.2f}, test_loss: {:.2f}, recon. loss: {:.2f}, KL div.: {:.2f}\".format(\n",
    "            epoch, train_loss, test_loss, rl, kl))\n",
    "        print(\"overfitting: {:.2f}\".format(abs(test_loss-train_loss)))\n",
    "plot_rl_kl(solver, solver.train_loss_history[\"recon_loss_acc\"], solver.train_loss_history[\"kl_diverg_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if solver.data_loader.thetas and solver.data_loader.scales:\n",
    "    rand_transformation = RandomPreprocessing(solver.data_loader.num_test_samples, solver.data_loader.img_dims,\\\n",
    "                                    solver.data_loader.theta_range_1, solver.data_loader.theta_range_2,\\\n",
    "                                    solver.data_loader.scale_range_1, solver.data_loader.scale_range_2)\n",
    "elif solver.data_loader.thetas:\n",
    "    rand_transformation = RandomPreprocessing(solver.data_loader.num_test_samples, solver.data_loader.img_dims,\\\n",
    "                                    solver.data_loader.theta_range_1, solver.data_loader.theta_range_2)\n",
    "elif solver.data_loader.scales:\n",
    "    rand_transformation = RandomPreprocessing(solver.data_loader.num_test_samples, solver.data_loader.img_dims,\\\n",
    "                                    scale_range_1=solver.data_loader.scale_range_1, scale_range_2=solver.data_loader.scale_range_2)\n",
    "z_space, y_space, _ = get_latent_spaces(solver, rand_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize q(z) (latent space z)\n",
    "if solver.model.z_dim == 2 and solver.data_loader.thetas or solver.data_loader.scales:\n",
    "    if solver.data_loader.thetas:\n",
    "        ticks = np.arange(solver.data_loader.theta_range_2[0], solver.data_loader.theta_range_2[1]+1, 10).tolist()\n",
    "        labels = rand_transformation.prepro_params[\"theta_diff\"].tolist()\n",
    "        plot_latent_space(solver, z_space, ticks=ticks, var=\"z\", title=\"theta\", labels=labels, colors=len(ticks)-1)\n",
    "    if solver.data_loader.scales:\n",
    "        ticks = [round(0.1*x,1) for x in range(int(solver.data_loader.scale_range_2[0]*10),\\\n",
    "                                                       int((solver.data_loader.scale_range_2[1]+0.1)*10))]\n",
    "        labels = rand_transformation.prepro_params[\"scale_diff\"].tolist()\n",
    "        plot_latent_space(solver, z_space, ticks=ticks, var=\"z\", title=\"scale\", labels=labels, colors=len(ticks)-1)\n",
    "else:\n",
    "    print(\"Plot of latent space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize q(y)\n",
    "if solver.model.z_dim == 2 and solver.data_loader.thetas or solver.data_loader.scales:\n",
    "    if solver.data_loader.thetas:\n",
    "        ticks = np.arange(solver.data_loader.theta_range_1[0], solver.data_loader.theta_range_1[1]+1, 30).tolist()\n",
    "        labels = rand_transformation.prepro_params[\"theta_1\"].tolist()\n",
    "        plot_latent_space(solver, y_space, ticks=ticks, var=\"y\", title=\"theta\", labels=labels)\n",
    "    if solver.data_loader.scales:\n",
    "        ticks = np.linspace(solver.data_loader.scale_range_1[0], solver.data_loader.scale_range_1[1], 13).tolist()\n",
    "        ticks = np.around(ticks, decimals=2)\n",
    "        labels = rand_transformation.prepro_params[\"scale_1\"].tolist()\n",
    "        plot_latent_space(solver, y_space, ticks=ticks, var=\"y\", title=\"scale\", labels=labels)\n",
    "else:\n",
    "    print(\"Plot of latent space not possible as dimension of z is not 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations of learned data manifold for generative models with two-dimensional latent space\n",
    "if solver.model.z_dim == 2:\n",
    "    n = 11\n",
    "    if solver.data_loader.thetas and solver.data_loader.scales:\n",
    "        grid_x = np.linspace(-2, 2, n)\n",
    "        grid_y = np.linspace(0, 3, n)\n",
    "    elif solver.data_loader.thetas:\n",
    "        grid_x = np.linspace(-4, 4, n)\n",
    "        grid_y = np.linspace(-4, 4, n)\n",
    "    elif solver.data_loader.scales:\n",
    "        grid_x = np.linspace(-3, 3, n)\n",
    "        grid_y = np.linspace(-3, 3, n)\n",
    "    test_loader = solver.data_loader.get_new_test_data_loader()\n",
    "    x_t = iter(test_loader).next()[0]\n",
    "    x_t, _ = rand_transformation.preprocess_batch(x_t)\n",
    "    x_t = x_t[0].view(-1, solver.data_loader.input_dim)\n",
    "    plot_latent_manifold(solver, \"bone\", grid_x, grid_y, n, x_t=x_t)\n",
    "else:\n",
    "    print(\"Plot is not possible as dimension of z is not 2 or model is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if solver.data_loader.thetas and solver.data_loader.scales and solver.model.z_dim == 2:\n",
    "    test_loader = solver.data_loader.get_new_test_data_loader()\n",
    "    num_rotations = 30\n",
    "    num_scales = 5\n",
    "    num_samples = 20\n",
    "    det_transformation = DeterministicPreprocessing(num_samples, solver.data_loader.img_dims,\\\n",
    "                                                num_rotations, num_scales, solver.data_loader.theta_range_1,\\\n",
    "                                                solver.data_loader.scale_range_1)\n",
    "    ys = np.zeros((det_transformation.scales.shape[0], det_transformation.thetas.shape[0], num_samples, 2))\n",
    "    transform_images(solver, det_transformation, test_loader, ys)\n",
    "    if solver.data_loader.directories.make_dirs:\n",
    "        torch.save(ys, solver.data_loader.directories.result_dir + \"/ys.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load y spaces for plotting\n",
    "# ys = torch.load(\"../results/tdcvae/MNIST_z=2_0/ys.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import skimage as ski\n",
    "test_loader = solver.data_loader.get_new_test_data_loader()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        data, y = data\n",
    "        data = data[:25].numpy()\n",
    "        #asd = torch.zeros((25, 1, 36, 36))\n",
    "        asd = np.zeros((25, 28, 28))\n",
    "        for i in range(25):\n",
    "            shift_y, shift_x = np.array(asd.shape[1:3]) / 2.\n",
    "            center_shift = ski.transform.SimilarityTransform(translation=[-shift_x, -shift_y])\n",
    "            center_shift_inv = ski.transform.SimilarityTransform(translation=[shift_x, shift_y])\n",
    "            center_transform = ski.transform.AffineTransform(scale=(1.0, 1.0), rotation=90)\n",
    "            transformation = center_shift + (center_transform + center_shift_inv)\n",
    "            print(data[i][0].shape)\n",
    "            asd[i] = ski.transform.warp(data[i][0], transformation.inverse, output_shape=(asd.shape[1], asd.shape[2]), preserve_range=True)\n",
    "            #asd[i] = transforms.ToTensor()(TF.resize(transforms.ToPILImage()(data[i]), (35, 35)))\n",
    "            #asd[i] = transforms.ToTensor()(TF.rotate(transforms.ToPILImage()(asd[i]), 270))\n",
    "        das = torch.tensor(asd)\n",
    "        das.unsqueeze_(1)\n",
    "        print(das.shape)\n",
    "        grid_img = torchvision.utils.make_grid(das, nrow=5)\n",
    "        plt.imshow(grid_img.permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(torch.FloatTensor(data), nrow=5)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import skimage as ski\n",
    "test_loader = solver.data_loader.get_new_test_data_loader()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        data, y = data\n",
    "        asd = torch.zeros((25, 1, 28, 28))\n",
    "        for i in range(25):\n",
    "            asd[i] = transforms.ToTensor()(TF.affine(transforms.ToPILImage()(data[i]), 180, [0, 0], 1.0, 0))\n",
    "            #asd[i] = TF.affine()\n",
    "        grid_img = torchvision.utils.make_grid(asd, nrow=5)\n",
    "        plt.imshow(grid_img.permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rotation\n",
    "if solver.z_dim == 2 and solver.data_loader.thetas:\n",
    "    plot_prepro_alpha_params_distribution(solver)\n",
    "else:\n",
    "    print(\"dim(z) is not 2 or rotation mode is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scaling\n",
    "if solver.z_dim == 2 and solver.data_loader.scales:\n",
    "    plot_prepro_radius_params_distribution(solver)\n",
    "else:\n",
    "    print(\"dim(z) is not 2 or scaling mode is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "plt.figure(figsize=(20,10))\n",
    "#print(ys[:,:,0,0].shape)\n",
    "#print(ys[:,:,0,0].shape)\n",
    "# ys = np.zeros((transformation.scales.shape[0], transformation.thetas.shape[0], solver.data_loader.num_test_samples, 2))\n",
    "for t in range(ys.shape[1]):\n",
    "  plt.scatter(ys[:,t,:,0], ys[:,t,:,1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for s in range(ys.shape[0]):\n",
    "  plt.scatter(ys[s,:,:,0],ys[s,:,:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute alphas\n",
    "ysflat=np.reshape(ys,(ys.shape[0]*ys.shape[1]*ys.shape[2], 2))\n",
    "meany=np.mean(ysflat, 0, keepdims=True)\n",
    "alphas= np.arctan2(ysflat[:,1]-meany[:,1], ysflat[:,0]-meany[:,0])\n",
    "# ys = np.zeros((transformation.scales.shape[0], transformation.thetas.shape[0], solver.data_loader.num_test_samples, 2))\n",
    "alphas= np.reshape(alphas, (ys.shape[2] * det_transformation.scales.shape[0], det_transformation.thetas.shape[0]))\n",
    "\n",
    "print(det_transformation.thetas.shape)\n",
    "print(np.min(alphas), np.max(alphas))\n",
    "print(alphas.shape)\n",
    "\n",
    "#normalize alpha[0]=theta[0]=0\n",
    "alphas -= alphas[:,0:1]\n",
    "alphas = alphas/(2*np.pi) * 360\n",
    "alphas = np.where(alphas > 0, alphas, alphas+360)\n",
    "\n",
    "\n",
    "thethos = np.repeat(det_transformation.thetas, alphas.shape[0])\n",
    "#print(np.min(alphas), np.max(alphas), alphas.shape)\n",
    "#print(thethos.shape, thethos[19998:20003])\n",
    "#plt.scatter(thetas[200,:], alphas[200,:])\n",
    "#plt.scatter(thetas[201,:], alphas[201,:])\n",
    "#thethos = transformation.thetas # np.tile(np.expand_dims(theta,axis=0),(alphas.shape[0],1))/(2*np.pi)/360\n",
    "#plt.figure(figsize=(20,10))\n",
    "\n",
    "print(thethos.shape, alphas.shape)\n",
    "plt.scatter(thethos.flatten(), alphas.flatten())\n",
    "plt.show()\n",
    "\n",
    "#plt.scatter(thethos[200:210], alphas[200:210])\n",
    "#plt.scatter(thethos[211], alphas[211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solver.data_loader.prepro_params[\"theta_1\"][1][100:200])\n",
    "print(solver.y_space.shape)\n",
    "N, M = solver.y_space.shape[1], solver.y_space.shape[0]\n",
    "# M, N, 2\n",
    "ysflat = np.reshape(solver.y_space, (N*M, 2)) # NM, 2\n",
    "meany = np.mean(ysflat, 0, keepdims=True) # 1, 2\n",
    "alphas = np.arctan2(ysflat[:,1]-meany[:,1], ysflat[:,0]-meany[:,0])\n",
    "alphas = np.reshape(alphas, (M, N)).T # 20*5, 30\n",
    "alphas -= alphas[:,0:1]\n",
    "alphas = alphas/(2*np.pi) * 360\n",
    "alphas = np.where(alphas >= 0, alphas, alphas+360)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"].T # M, N\n",
    "print(alphas.shape, np.min(alphas), np.max(alphas))\n",
    "print(\"thetas\", thetas.shape, np.min(ysflat), np.max(ysflat))\n",
    "\n",
    "#scatter = ax.scatter(thetas.flatten(), alphas.flatten())\n",
    "print(thetas[200,:], alphas[200,:])\n",
    "plt.scatter(thetas[200,:], alphas[200,:])\n",
    "plt.scatter(thetas[201,:], alphas[201,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "\n",
    "alphas = torch.atan2(torch.tensor(solver.y_space[:,:,0]-np.mean(solver.y_space[:,:,0])), torch.tensor(solver.y_space[:,:,1]-np.mean(solver.y_space[:,:,1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "# TODO:\n",
    "alphas = alphas[0,:]\n",
    "classes = solver.data_labels\n",
    "alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:]))\n",
    "\n",
    "# TODO: fix thetas...\n",
    "print(alphas.shape)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"][0] #np.radians(solver.data_loader.prepro_params[\"theta_1\"][0].T)\n",
    "print(thetas)\n",
    "print(np.min(thetas), np.max(thetas))\n",
    "\n",
    "#paired_cmap = plt.cm.get_cmap(\"Paired\", 12)\n",
    "#rvb = mcolors.LinearSegmentedColormap.from_list(\"\", paired_cmap.colors)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "#norm = (alpha_ranges - np.min(alpha_ranges))/np.ptp(alpha_ranges)\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for alpha in alphas_indices:\n",
    "        for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "            if x <= alpha and alpha < y:\n",
    "                counts[bin_idx] += 1\n",
    "                break\n",
    "    print(counts)\n",
    "    new_counts = np.zeros(len(alphas_indices))\n",
    "    asd = 0\n",
    "    for idx, count in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    print(len(thetas), len(new_counts), indices, np.min(thetas[indices]), np.max(thetas[indices]))\n",
    "    scatter = ax.scatter(thetas[indices], alphas_indices, c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "solver = torch.load(\"../results/saved_models/model_TD_CVAE_MNIST_train_loss=88.61_z=2.pt\", map_location='cpu')\n",
    "#solver = torch.load(\"../results/saved_models/model_TD_CVAE_THETAS_MNIST_train_loss=86.61_z=2.pt\", map_location='cpu')\n",
    "solver.model.eval()\n",
    "\n",
    "\n",
    "alphas = torch.atan2(torch.tensor(solver.y_space[:,0]-np.mean(solver.y_space[:,0])), torch.tensor(solver.y_space[:,1]-np.mean(solver.y_space[:,1])))/(2*np.pi)\n",
    "alphas = np.array([round(x,2) for x in alphas.tolist()])\n",
    "# TODO: problem: for each batch_size, there are num_generation (thetas, alphas), we have to take that into account!\n",
    "#thetas = np.repeat(solver.data_loader.prepro_params[\"theta_1\"], solver.data_loader.batch_size)\n",
    "classes = np.array(solver.data_labels)\n",
    "#y_space_labels = np.repeat(solver.data_loader.prepro_params[key], solver.data_loader.batch_size)\n",
    "alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "#print(solver.data_loader.prepro_params[\"theta_1\"], solver.data_loader.batch_size)\n",
    "# TODO: make alphas bins and count, but then flatten the counts, and mark by counts values where each new color begins.\n",
    "#print(np.sum(counts))\n",
    "#print(alphas.shape, len(thetas), solver.y_space.shape, len(solver.data_loader.prepro_params[\"theta_1\"]), classes)\n",
    "# move every 10, because every 10th is the angle for index 0.\n",
    "thetas = np.repeat(np.array(solver.data_loader.prepro_params[\"theta_1\"][::solver.num_generations]), solver.data_loader.batch_size)\n",
    "print(thetas.shape)\n",
    "\n",
    "paired_cmap = plt.cm.get_cmap(\"Paired\", 12)\n",
    "rvb = mcolors.LinearSegmentedColormap.from_list(\"\", paired_cmap.colors)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "norm = (alpha_ranges - np.min(alpha_ranges))/np.ptp(alpha_ranges)\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "print(alpha_bins)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for alpha in alphas_indices:\n",
    "        for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "            if x <= alpha and alpha < y:\n",
    "                counts[bin_idx] += 1\n",
    "                break\n",
    "    print(counts)\n",
    "    #print(counts.sum(), len(alphas_indices))\n",
    "    #print(counts)\n",
    "    new_counts = np.zeros(len(alphas_indices))\n",
    "    asd = 0\n",
    "    for idx, count in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        #print(asd, offset, to_fill.shape)\n",
    "        new_counts[asd:(asd+offset)] = to_fill # 0:len(to_fill), len(to_fill):len(new_to_fill)\n",
    "        asd += offset\n",
    "    print(len(new_counts))\n",
    "    scatter = ax.scatter(thetas[indices], alphas_indices, c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver = torch.load(\"../results/saved_models/model_TD_CVAE_THETAS_MNIST_train_loss=86.61_z=2.pt\", map_location='cpu')\n",
    "#solver.model.eval()\n",
    "# compute the alphas\n",
    "alphas = torch.zeros((solver.y_space.shape[0], solver.num_generations)) # solver.num_generations\n",
    "for idx, gen_idx in enumerate(range(0, solver.num_generations*2, 2)): # solver.num_generations*2, 2\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[:, gen_idx]-np.mean(solver.y_space[:, gen_idx])),\\\n",
    "            torch.tensor(solver.y_space[:, gen_idx+1]-np.mean(solver.y_space[:, gen_idx+1])))/(2*np.pi)\n",
    "    # normalizing alpha_{ij} = alpha_{ij} - alpha_{i0}\n",
    "    #if idx > 0:\n",
    "    #    alphas[:, idx] -= alphas[:, 0]\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "# prepare the thetas from each batch, repeat each set of theta to span over num train samples\n",
    "thetas = np.zeros((solver.data_loader.num_train_samples, solver.num_generations))\n",
    "for gen in range(solver.num_generations):\n",
    "    thetas[:, gen] = np.radians(np.repeat(solver.data_loader.prepro_params[\"theta_1\"][gen::solver.num_generations], solver.data_loader.batch_size))\n",
    "#thetas = np.repeat(np.array(solver.data_loader.prepro_params[\"theta_1\"][::solver.num_generations]), solver.data_loader.batch_size)\n",
    "print(alphas.shape, thetas.shape)\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "    \n",
    "print(alphas.shape, thetas.shape)\n",
    "    #paired_cmap = plt.cm.get_cmap(\"Paired\", 12)\n",
    "    #rvb = mcolors.LinearSegmentedColormap.from_list(\"\", paired_cmap.colors)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "    #norm = (alpha_ranges - np.min(alpha_ranges))/np.ptp(alpha_ranges)\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = np.array(solver.data_labels)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for i in range(alphas.shape[1]):\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    scatter = ax.scatter(thetas[indices].flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver = torch.load(\"../results/saved_models/model_TD_CVAE_THETAS_MNIST_train_loss=86.61_z=2.pt\", map_location='cpu')\n",
    "#solver.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "# compute the alphas\n",
    "alphas = torch.zeros((solver.y_space.shape[0], solver.num_generations)) # solver.num_generations\n",
    "for idx, gen_idx in enumerate(range(0, solver.num_generations*2, 2)): # solver.num_generations*2, 2\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[:, gen_idx]-np.mean(solver.y_space[:, gen_idx])),\\\n",
    "            torch.tensor(solver.y_space[:, gen_idx+1]-np.mean(solver.y_space[:, gen_idx+1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "\n",
    "# prepare the thetas from each batch, repeat each set of theta to span over num train samples\n",
    "thetas = np.zeros((solver.data_loader.num_train_samples, solver.num_generations))\n",
    "# For each batch we go through num_generations iterations/encodings. Thus, \n",
    "# if num_generations is 10, for prepro_params, 0-9 is for batch 0, 10-19 for batch 1 and so on. (every time on the same batch)  \n",
    "idx = 0\n",
    "for batch_idx in range(solver.data_loader.num_train_batches):\n",
    "    start = batch_idx*solver.data_loader.batch_size\n",
    "    end = (batch_idx+1)*solver.data_loader.batch_size\n",
    "    for gen in range(solver.num_generations):\n",
    "        thetas[start:end, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][idx], solver.data_loader.batch_size)\n",
    "        idx += 1\n",
    "    #thetas[:, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "print(mini, maxi)\n",
    "for idx in range(0, alphas.shape[1]):\n",
    "    # normalizing alpha_{ij} = alpha_{ij} - alpha_{i0}\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] = np.around(alphas[:, idx] - alphas[:, 0] + (np.radians(thetas[:, 0])/(2*np.pi))-0.5, decimals=2)\n",
    "        #mini = np.min(alphas[:, idx])\n",
    "        #maxi = np.max(alphas[:, idx])\n",
    "        #print(mini, maxi)\n",
    "        #print(np.min(alphas[:, idx]), np.max(alphas[:, idx]))\n",
    "        neg_indices = np.where(alphas[:, idx] < -0.5)\n",
    "        pos_indices = np.where(alphas[:, idx] > 0.5)\n",
    "        alphas[neg_indices, idx] = mini % alphas[neg_indices, idx]\n",
    "        alphas[pos_indices, idx] = maxi % alphas[pos_indices, idx]\n",
    "        print(np.min(alphas[:, idx]), np.max(alphas[:, idx]))\n",
    "\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = np.array(solver.data_labels)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for i in range(alphas.shape[1]):\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    scatter = ax.scatter(np.radians(thetas[indices].flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "'''\n",
    "alphas = torch.atan2(torch.tensor(solver.y_space[:,:,0]-np.mean(solver.y_space[:,:,0])), torch.tensor(solver.y_space[:,:,1]-np.mean(solver.y_space[:,:,1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "# TODO:\n",
    "alphas = alphas[0,:]\n",
    "classes = solver.data_labels\n",
    "alpha_ranges = np.around(np.linspace(np.min(alphas), np.max(alphas), 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:]))\n",
    "\n",
    "# TODO: fix thetas...\n",
    "print(alphas.shape)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"][0] #np.radians(solver.data_loader.prepro_params[\"theta_1\"][0].T)\n",
    "print(thetas)\n",
    "print(np.min(thetas), np.max(thetas))\n",
    "\n",
    "# compute the alphas\n",
    "M, N, D = solver.y_space.shape\n",
    "new_y_space = solver.y_space.reshape((N, M, D))\n",
    "alphas = torch.zeros((new_y_space.shape[1], new_y_space.shape[2])) # used to be N, D\n",
    "thetas = np.zeros_like(alphas)\n",
    "#print(solver.y_space.shape, new_y_space.shape, alphas.shape)\n",
    "#print(torch.tensor(solver.y_space[: idx, 0]-np.mean(solver.y_space[:, idx, 0])).shape)\n",
    "for idx in range(solver.y_space.shape[0]):\n",
    "    print(\"haha\", (torch.tensor(new_y_space[: idx, 0]-np.mean(new_y_space[:, idx, 0]))))\n",
    "    #alphas[:, idx] = torch.atan2(torch.tensor(new_y_space[: idx, 0]-np.mean(new_y_space[:, idx, 0])),\\\n",
    "    #        torch.tensor(new_y_space[:, idx, 1]-np.mean(new_y_space[:, idx, 1])))/(2*np.pi)\n",
    "    #thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    #if idx > 0:\n",
    "    #    alphas[:, idx] -= alphas[:, 0]\n",
    "\n",
    "# TODO:oK?\n",
    "alphas = torch.zeros((solver.y_space.shape[1], solver.y_space.shape[0]))\n",
    "thetas = np.zeros_like(alphas)\n",
    "for idx in range(solver.y_space.shape[0]):\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[idx, :, 0]-np.mean(solver.y_space[idx, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[idx, :, 1]-np.mean(solver.y_space[idx, :, 1])))/(2*np.pi)\n",
    "    thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] = alphas[:, idx]\n",
    "'''\n",
    "\n",
    "# M, N, 2\n",
    "print(solver.data_loader.prepro_params[\"theta_1\"].shape)\n",
    "N, M = solver.y_space.shape[1], solver.y_space.shape[0]\n",
    "alphas = torch.zeros((N, M))\n",
    "thetas = np.zeros_like(alphas)\n",
    "for idx in range(M):\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[idx, :, 0]-np.mean(solver.y_space[idx, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[idx, :, 1]-np.mean(solver.y_space[idx, :, 1])))/(2*np.pi)\n",
    "    thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] -= alphas[:, 0]\n",
    "        \n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "print(mini, maxi)\n",
    "print(alphas.shape, thetas.shape)\n",
    "print(thetas[100:200])\n",
    "\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, M), decimals=2)\n",
    "alpha_ranges = alpha_ranges[:-1]\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "# figures\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = solver.data_labels\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices]\n",
    "    for i in range(alphas.shape[1]):\n",
    "        print(i, alphas_indices[:, i].shape)\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    #print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    print(len(thetas[indices].flatten()), len(alphas_indices.flatten()))\n",
    "    scatter = ax.scatter(thetas[indices].flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "plt.figure(figsize=(20,10))\n",
    "#print(ys[:,:,0,0].shape)\n",
    "#print(ys[:,:,0,0].shape)\n",
    "# ys = np.zeros((transformation.scales.shape[0], transformation.thetas.shape[0], solver.data_loader.num_test_samples, 2))\n",
    "for t in range(ys.shape[1]):\n",
    "  plt.scatter(ys[:,t,:,0], ys[:,t,:,1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for s in range(ys.shape[0]):\n",
    "  plt.scatter(ys[s,:,:,0],ys[s,:,:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute alphas\n",
    "ysflat=np.reshape(ys,(ys.shape[0]*ys.shape[1]*ys.shape[2], 2))\n",
    "meany=np.mean(ysflat, 0, keepdims=True)\n",
    "alphas= np.arctan2(ysflat[:,1]-meany[:,1], ysflat[:,0]-meany[:,0])\n",
    "# ys = np.zeros((transformation.scales.shape[0], transformation.thetas.shape[0], solver.data_loader.num_test_samples, 2))\n",
    "alphas= np.reshape(alphas, (ys.shape[2] * det_transformation.scales.shape[0], det_transformation.thetas.shape[0]))\n",
    "\n",
    "print(det_transformation.thetas.shape)\n",
    "print(np.min(alphas), np.max(alphas))\n",
    "print(alphas.shape)\n",
    "\n",
    "#normalize alpha[0]=theta[0]=0\n",
    "alphas -= alphas[:,0:1]\n",
    "alphas = alphas/(2*np.pi) * 360\n",
    "alphas = np.where(alphas > 0, alphas, alphas+360)\n",
    "\n",
    "\n",
    "thethos = np.repeat(det_transformation.thetas, alphas.shape[0])\n",
    "#print(np.min(alphas), np.max(alphas), alphas.shape)\n",
    "#print(thethos.shape, thethos[19998:20003])\n",
    "#plt.scatter(thetas[200,:], alphas[200,:])\n",
    "#plt.scatter(thetas[201,:], alphas[201,:])\n",
    "#thethos = transformation.thetas # np.tile(np.expand_dims(theta,axis=0),(alphas.shape[0],1))/(2*np.pi)/360\n",
    "#plt.figure(figsize=(20,10))\n",
    "plt.scatter(thethos.flatten(), alphas.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solver.data_loader.prepro_params[\"theta_1\"][1][100:200])\n",
    "print(solver.y_space.shape)\n",
    "N, M = solver.y_space.shape[1], solver.y_space.shape[0]\n",
    "# M, N, 2\n",
    "ysflat = np.reshape(solver.y_space, (N*M, 2)) # NM, 2\n",
    "meany = np.mean(ysflat, 0, keepdims=True) # 1, 2\n",
    "alphas = np.arctan2(ysflat[:,1]-meany[:,1], ysflat[:,0]-meany[:,0])\n",
    "alphas = np.reshape(alphas, (M, N)).T # 20*5, 30\n",
    "alphas -= alphas[:,0:1]\n",
    "alphas = alphas/(2*np.pi) * 360\n",
    "alphas = np.where(alphas >= 0, alphas, alphas+360)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"].T # M, N\n",
    "print(alphas.shape, np.min(alphas), np.max(alphas))\n",
    "print(\"thetas\", thetas.shape, np.min(ysflat), np.max(ysflat))\n",
    "\n",
    "#scatter = ax.scatter(thetas.flatten(), alphas.flatten())\n",
    "print(thetas[200,:], alphas[200,:])\n",
    "plt.scatter(thetas[200,:], alphas[200,:])\n",
    "plt.scatter(thetas[201,:], alphas[201,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as bla\n",
    "\n",
    "######################################################################\n",
    "\n",
    "#solver = torch.load(\"../results/show_oswin/29/model_TD_CVAE_THETAS_MNIST_train_loss=158.23_z=2.pt\", map_location='cpu')\n",
    "#solver.model.eval()\n",
    "\n",
    "N, M = ys\n",
    "M = 2\n",
    "alphas = np.zeros((N, M))\n",
    "thetas = np.zeros_like(alphas)\n",
    "alphas[:, 0] = torch.atan2(torch.tensor(solver.y_space[0, :, 0]-np.mean(solver.y_space[0, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[0, :, 1]-np.mean(solver.y_space[0, :, 1])))\n",
    "alphas[:, 1] = torch.atan2(torch.tensor(solver.y_space[1, :, 0]-np.mean(solver.y_space[1, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[1, :, 1]-np.mean(solver.y_space[1, :, 1])))\n",
    "alphas = np.array(alphas)\n",
    "alphas[:, 1] -= alphas[:, 0]\n",
    "alphas /= (2*np.pi)/360\n",
    "alphas = np.around(alphas, decimals=2)\n",
    "thetas[:, 0] = solver.data_loader.prepro_params[\"theta_1\"][0]\n",
    "thetas[:, 1] = solver.data_loader.prepro_params[\"theta_1\"][1]\n",
    "alphas = np.where(alphas >= 0, alphas, alphas+360)\n",
    "\n",
    "print(thetas[:, 0])\n",
    "print(thetas[:, 1])\n",
    "\n",
    "'''\n",
    "M=1\n",
    "alphas = torch.zeros((N, 1))\n",
    "thetas = np.zeros_like(alphas)\n",
    "alphas[:, 0] = torch.atan2(torch.tensor(solver.y_space[0, :, 0]-np.mean(solver.y_space[0, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[0, :, 1]-np.mean(solver.y_space[0, :, 1])))/(2*np.pi)\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "thetas[:, 0] = solver.data_loader.prepro_params[\"theta_1\"][0]\n",
    "'''\n",
    "\n",
    "'''\n",
    "N, M = solver.y_space.shape[1], solver.y_space.shape[0]\n",
    "alphas = torch.zeros((N, M))\n",
    "thetas = np.zeros_like(alphas)\n",
    "for idx in range(M):\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[idx, :, 0]-np.mean(solver.y_space[idx, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[idx, :, 1]-np.mean(solver.y_space[idx, :, 1])))/(2*np.pi)\n",
    "    thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    alphas = np.around(np.array(alphas), decimals=2)\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] -= alphas[:, 0]\n",
    "        #neg_indices = np.where(alphas[:, idx] < -0.5)\n",
    "        #pos_indices = np.where(alphas[:, idx] > 0.5)\n",
    "        #alphas[neg_indices, idx] = mini % alphas[neg_indices, idx]\n",
    "        #alphas[pos_indices, idx] = maxi % alphas[pos_indices, idx]\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "'''\n",
    "#solver = torch.load(\"../results/show_oswin/29/model_TD_CVAE_THETAS_MNIST_train_loss=158.23_z=2.pt\", map_location='cpu')\n",
    "#solver.model.eval()\n",
    "\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "print(alphas.shape)\n",
    "# figures\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = solver.data_labels\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices, 1:] # , 1:\n",
    "    for i in range(alphas_indices.shape[1]):\n",
    "        print(i, alphas_indices.shape)\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    thets = thetas[indices, 1:] # , 1:\n",
    "    #print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    print(len(thets.flatten()), len(alphas_indices.flatten()))\n",
    "    scatter = ax.scatter(thets.flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#compute alphas\n",
    "ysflat=np.reshape(ys,(ys.shape[0]*ys.shape[1] * ys.shape[2],2))\n",
    "meany=np.mean(ysflat,0,keepdims=True)\n",
    "alphas= np.arctan2(ysflat[:,1]-meany[:,1], ysflat[:,0]-meany[:,0])\n",
    "alphas= np.reshape(alphas,(ys.shape[0] * s.shape[0], theta.shape[0]))\n",
    "\n",
    "#normalize alpha[0]=theta[0]=0\n",
    "alphas -= alphas[:,0:1]\n",
    "alphas = alphas/(2*np.pi) * 360\n",
    "alphas = np.where(alphas > 0, alphas, alphas+360)\n",
    "'''\n",
    "solver = torch.load(\"../results/show_oswin/29/model_TD_CVAE_THETAS_MNIST_train_loss=158.23_z=2.pt\", map_location='cpu')\n",
    "solver.model.eval()\n",
    "\n",
    "print(solver.data_loader.prepro_params[\"theta_1\"][1][100:200])\n",
    "print(solver.y_space.shape)\n",
    "N, M = solver.y_space.shape[1], solver.y_space.shape[0]\n",
    "# M, N, 2\n",
    "ysflat = np.reshape(solver.y_space, (N*M, 2)) # NM, 2\n",
    "meany = np.mean(ysflat, 0, keepdims=True) # 1, 2\n",
    "alphas = np.arctan2(ysflat[:,1]-meany[:,1], ysflat[:,0]-meany[:,0])\n",
    "alphas = np.reshape(alphas, (M, N)).T # 20*5, 30\n",
    "alphas -= alphas[:,0:1]\n",
    "alphas = alphas/(2*np.pi) * 360\n",
    "alphas = np.where(alphas >= 0, alphas, alphas+360)\n",
    "thetas = solver.data_loader.prepro_params[\"theta_1\"].T # M, N\n",
    "print(alphas.shape, np.min(alphas), np.max(alphas))\n",
    "print(\"thetas\", thetas.shape, np.min(ysflat), np.max(ysflat))\n",
    "\n",
    "#scatter = ax.scatter(thetas.flatten(), alphas.flatten())\n",
    "print(thetas[200,:], alphas[200,:])\n",
    "plt.scatter(thetas[200,:], alphas[200,:])\n",
    "plt.scatter(thetas[201,:], alphas[201,:])\n",
    "'''\n",
    "for idx in range(M):\n",
    "    alphas[:, idx] = torch.atan2(torch.tensor(solver.y_space[idx, :, 0]-np.mean(solver.y_space[idx, :, 0])),\\\n",
    "            torch.tensor(solver.y_space[idx, :, 1]-np.mean(solver.y_space[idx, :, 1])))/(2*np.pi)\n",
    "    thetas[:, idx] = solver.data_loader.prepro_params[\"theta_1\"][idx]\n",
    "    alphas = np.around(np.array(alphas), decimals=2)\n",
    "    if idx > 0:\n",
    "        alphas[:, idx] -= alphas[:, 0]\n",
    "alphas = np.around(np.array(alphas), decimals=2)\n",
    "'''\n",
    "\n",
    "'''\n",
    "mini = np.min(alphas)\n",
    "maxi = np.max(alphas)\n",
    "# create the alphas bins, corresponding to the same number as theta bins\n",
    "alpha_ranges = np.around(np.linspace(mini, maxi, 13), decimals=2)\n",
    "alpha_bins = list(zip(alpha_ranges[:-1], alpha_ranges[1:])) # alpha bins\n",
    "print(alphas.shape)\n",
    "# figures\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10,60))\n",
    "classes = solver.data_labels\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(alpha_bins))\n",
    "    alphas_indices = alphas[indices] # , 1:\n",
    "    for i in range(alphas_indices.shape[1]):\n",
    "        print(i, alphas_indices.shape)\n",
    "        for alpha in alphas_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(alpha_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(alphas_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    thets = thetas[indices] # , 1:\n",
    "    #print(len(thetas[indices].flatten()), len(alphas_indices), new_counts.shape, indices.shape)\n",
    "    print(len(thets.flatten()), len(alphas_indices.flatten()))\n",
    "    scatter = ax.scatter(thets.flatten(), alphas_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiuses = np.zeros((solver.y_space.shape[0], solver.num_generations))\n",
    "centroid = np.mean(solver.y_space[:, :2], axis=0)\n",
    "# compute the euclidean distance from each point y_{ij} to the center, so the radiuses\n",
    "#print(solver.data_loader.train_loader.dataset.transform.transforms.prepro_params)\n",
    "#print(solver.data_loader.prepro_params[\"scale_1\"])\n",
    "for idx, gen_idx in enumerate(range(0, solver.num_generations*2, 2)):\n",
    "    radiuses[:, idx] = bla.cdist(solver.y_space[:, gen_idx:gen_idx+2], np.atleast_2d(centroid)).ravel()\n",
    "    if idx > 0:\n",
    "        radiuses[:, idx] -= radiuses[:, 0]\n",
    "    #radiuses = np.around(np.array(radiuses), decimals=2)\n",
    "    # prepare the scale from each batch, repeat each set of scales to span over num train samples\n",
    "#print(solver.data_loader.prepro_params)\n",
    "scales = np.zeros((solver.data_loader.num_train_samples, solver.num_generations))\n",
    "for idx in range(solver.num_generations):\n",
    "    #thetas[:, gen] = np.repeat(solver.data_loader.prepro_params[\"theta_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "    scales[:, idx] = np.repeat(solver.data_loader.prepro_params[\"scale_1\"][gen::solver.num_generations], solver.data_loader.batch_size)\n",
    "    # create the alphas bins, corresponding to the same number as theta bins\n",
    "mini = np.min(radiuses)\n",
    "maxi = np.max(radiuses)\n",
    "radius_ranges = np.around(np.linspace(mini, maxi, 5), decimals=2)\n",
    "radius_bins = list(zip(radius_ranges[:-1], radius_ranges[1:]))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=solver.data_loader.n_classes, figsize=(10, 60))\n",
    "classes = np.array(solver.data_labels)\n",
    "for ax, label in zip(axes.flat, range(solver.data_loader.n_classes)):\n",
    "    indices = np.where(classes == label)[0]\n",
    "    ax.set_title(\"class: {}\".format(label))\n",
    "    counts = np.zeros(len(radius_bins))\n",
    "    radius_indices = radiuses[indices]\n",
    "    for i in range(radiuses.shape[1]):\n",
    "        for alpha in radius_indices[:, i]:\n",
    "            for bin_idx, (x, y) in enumerate(radius_bins):\n",
    "                if x <= alpha and alpha < y:\n",
    "                    counts[bin_idx] += 1\n",
    "                    break\n",
    "    new_counts = np.zeros(np.prod(radius_indices.shape))\n",
    "    asd = 0\n",
    "    for idx, _ in enumerate(counts):\n",
    "        to_fill = counts[idx].repeat(counts[idx])\n",
    "        offset = len(to_fill)\n",
    "        new_counts[asd:(asd+offset)] = to_fill\n",
    "        asd += offset\n",
    "    scatter = ax.scatter(scales[indices, :].flatten(), radius_indices.flatten(), c=new_counts, cmap=plt.cm.get_cmap(\"Paired\", 12))\n",
    "    fig.colorbar(scatter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_loss = solver.train_loss_history[\"train_loss_acc\"][-1]\n",
    "mode = \"\"\n",
    "if solver.data_loader.thetas and solver.data_loader.scales:\n",
    "    mode = \"SCALES_THETAS_\"\n",
    "elif solver.data_loader.thetas:\n",
    "    mode += \"THETAS_\"\n",
    "elif solver.data_loader.scales:\n",
    "    mode += \"SCALES_\"\n",
    "torch.save(solver, solver.data_loader.directories.result_dir + \"/model_TD_CVAE_\" + mode + solver.data_loader.dataset + \"_train_loss=\" + \"{0:.2f}\".format(last_train_loss) + \"_z=\" + str(solver.z_dim) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
